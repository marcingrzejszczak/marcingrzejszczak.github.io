<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Micro-infra-spring | TOO MUCH CODING]]></title>
  <link href="http://toomuchcoding.com/blog/categories/micro-infra-spring/atom.xml" rel="self"/>
  <link href="http://toomuchcoding.com/"/>
  <updated>2018-09-17T10:29:39+02:00</updated>
  <id>http://toomuchcoding.com/</id>
  <author>
    <name><![CDATA[Marcin Grzejszczak]]></name>
    <email><![CDATA[blog@toomuchcoding.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Microservice Deployment]]></title>
    <link href="http://toomuchcoding.com/blog/2015/09/26/microservice-deployment/"/>
    <updated>2015-09-26T15:13:00-07:00</updated>
    <id>http://toomuchcoding.com/blog/2015/09/26/microservice-deployment</id>
    <content type="html"><![CDATA[<div class='post'>
It's been a while since my last post. In the meantime of course nothing has changed in terms of the microservice hype. I've been &nbsp;attending many microservice's talks and what I'm always missing are concrete details on many different subjects. One of which is deployment. In this post I'll try to depict how in a big, multinational company one would want to do microservice deployment. I'll walk you through the most basic deployment pipeline that could be created in such an enterprise.<br /><br /><a name='more'></a>
<!--more-->
<br /><h4>The goal</h4>Our goal was to:<br /><br /><b>Enforce standards</b><br /><b><br /></b>Have a unique way of deploying alll microservices - we need to enforce standards<br /><br /><b>Tackle the microservice dependencies complexity issue</b><br /><br />Make the deployment process maintainable from the infrastructure and operations perspective<br /><br /><b>Make the pipeline fast and certain</b><br /><br />Have the greatest possible certainty that our features are working fine.<br />We wanted to make the deployment pipeline as fast as possible.<br />It was crucial to add the possibility to automatically rollback if something goes wrong.<br /><br /><h4>Enforce standards</h4>It is crucial that if you're starting with microservices you start introducing standards. Standards of running applications, configuring them (externalized properties) but also you should enforce standards in how you deploy your applications. At some point in time we have seen that different applications do common tasks in different ways.<br /><br />Why should we bother - we have business value to deliver and not waste time on enforcing standards - your manager might say. Actually he is really wrong because you're wasting plenty of time (thus money) on supporting such nonstandard applications. Imagine how much it needs for the new developers to understand how exactly the rules are set in this particular process.<br /><br />The same relates to deployment and deployment pipelines. That's why we decided to enforce one, single way of deploying microservices.<br /><br /><h4><span style="font-weight: normal;">Tackle the microservice dependencies complexity issue</span></h4><br />If you have two monolithic applications talking to each other and not too many developers working on the codebases you can queue deployment of both apps and always perform end to end tests.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-G80VsWKpIy0/VgbyR9nENVI/AAAAAAABII4/rYV8ZIMJi6A/s1600/monolith.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="124" src="https://2.bp.blogspot.com/-G80VsWKpIy0/VgbyR9nENVI/AAAAAAABII4/rYV8ZIMJi6A/s320/monolith.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Two monolithic applications deployed for end to end testing</td></tr></tbody></table><div class="separator" style="clear: both; text-align: left;">In case of microservices the scale starts to be a problem:</div><div class="separator" style="clear: both; text-align: left;"><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-kggPwWHR-iQ/VgbyhX1x5aI/AAAAAAABIJA/tf2lLkCruxA/s1600/many_microservices.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="207" src="https://2.bp.blogspot.com/-kggPwWHR-iQ/VgbyhX1x5aI/AAAAAAABIJA/tf2lLkCruxA/s320/many_microservices.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Many microservices deployed in different versions</td></tr></tbody></table><div class="separator" style="clear: both; text-align: left;">The questions arise:</div><div class="separator" style="clear: both; text-align: left;"></div><ul><li>Should I queue deployments of microservices on one testing environment or should I have an environment per microservice?&nbsp;</li><ul><li>If I queue deployments people will have to wait for hours to have their tests ran - that can be a problem</li></ul><li>To remove that issue I can have an environment per microservice&nbsp;</li><ul><li>Who will pay the bills (imagine 100 microservices - each having each own environment).&nbsp;</li><li>Who will support each of those environments?</li><li>Should we spawn a new environment each time we execute a new pipeline and then wrap it up or should we have them up and running for the whole day?</li></ul><li>In which versions should I deploy the dependent microservices - development or production versions?</li><ul><li>If I have development versions then I can test my application against a feature that is not yet on production. That can lead to exceptions on production</li><li>If I test against production versions then I'll never be able to test against a feature under development anytime before deployment to production.</li></ul></ul><h4>Make the pipeline fast and certain</h4><div><br /></div><div>Since we really believe in the agile methodology and continuous deployment we would like our features to be delivered to production as fast as possible. When working with the monolithic applications we've faced the following issues:</div><div><ul><li>For monolithic applications we had plenty of unit, integration and end to end tests</li><li>The different types of tests covered the same functionality up to three times</li><li>The tests took a lot of time to run</li></ul><div>Having all of this in mind we wanted not to have such issues with our new deployment pipeline.</div><div><br /></div></div><br /><div class="separator" style="clear: both; text-align: left;"></div><h4>Simplify the infrastructure complexity</h4><div><br /></div><div>Due to technical issues, difficulties to maintain the spawned environments we've decided to simplify the pipeline as much as possible. That's why since we are enthusiasts of TDD and we know what Consumer Driven Contract is we've decided not to do End to End tests. We're deploying our application to a virtual machine where the executed tests don't interfere with other pipelines executed in the very same time.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-3BIKN1VzDKA/Vgb7oxk8jXI/AAAAAAABIJQ/q_A0LifBgEI/s1600/stubbed_dependencies.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="203" src="https://3.bp.blogspot.com/-3BIKN1VzDKA/Vgb7oxk8jXI/AAAAAAABIJQ/q_A0LifBgEI/s320/stubbed_dependencies.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Execute tests on a deployed microservice on stubbed dependencies</td></tr></tbody></table><div>That way you can look at your application tests (we called them smoke tests) in the following way:</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-7jseO68-q6A/Vgb8h7Ia1CI/AAAAAAABIJc/C8W0S4qZAic/s1600/no_e2e_tests.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="303" src="https://3.bp.blogspot.com/-7jseO68-q6A/Vgb8h7Ia1CI/AAAAAAABIJc/C8W0S4qZAic/s320/no_e2e_tests.png" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">We're testing microservices in isolation</td></tr></tbody></table><div>Why smoke tests? Because we deliberately want to enforce the testing pyramid in the following way:</div><div><ul><li>A lot of unit tests executed during build time</li><li>Some integration tests running on stubs of dependent services executed during build time</li><li>Not many acceptance tests&nbsp;running on stubs of dependent services executed during build time (these can be treated as special case of integration tests)</li><li>A handful of smoke tests executed on a deployed application to see if the app is really packaged properly</li></ul></div><div><br /></div><div>Such an approach to testing and deployment gives the following benefits:</div><div><ul><li>No need to deploy dependent services</li><li>The stubs used for the tests ran on a deployed microservice are the same as those used during integration tests</li><li>Those stubs have been tested against the application that produces them (check <a href="https://github.com/Codearte/accurest">Accurest</a> for more information)</li><li>We don't have many slow tests running on a deployed application - thus the pipeline gets executed much faster</li><li>We don't have to queue deployments - we're testing in isolation thus pipelines don't interfere with each other</li><li>We don't have to spawn virtual machines each time for deployment purposes</li></ul></div><div><br /></div><div>It brings however the following challenges:</div><div><ul><li>No end to end tests before production - you don't have the full certainty that a feature is working</li><li>Due to this certainty that the functionality is working decreases</li><li>First time the applications will talk in a real way will be on production</li></ul></div><h4>Overcoming fear of uncertainty</h4><div><br /></div><div>The argument that we don't know if a functionality is working properly made us invest more time and effort in tools that will give us more information on how our applications work on production. That's why we've added plenty of monitoring both technical and business via Graphite. Also we've introduced Seyren as the alerting mechanism to ping us immediately when something is really wrong on production.</div><div><br /></div><div>Whatever time you spend on improving your tests, testing environments or UATs with endless hours of clicking - it will never signify that on production your application will run in the same manner.</div><div><br /></div><div>Our decisions were related to trade offs. We decided to give away the complexity in the artificial test environments. That complexity was pushed to the monitoring of production instances. With microservices there is never an easy decision - there's always some price needed to pay.</div><div><br /></div><h4>The technical overview of the solution</h4><div><br /></div><div>We've divided the simplest scenario of the microservice deployment pipeline into the following steps.</div><div><br /></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-JmkGUgmrI8Q/Vgb-y9Eg9RI/AAAAAAABIJo/QMa0rkaSfUk/s1600/Microservice%2BPipeline.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="305" src="https://4.bp.blogspot.com/-JmkGUgmrI8Q/Vgb-y9Eg9RI/AAAAAAABIJo/QMa0rkaSfUk/s640/Microservice%2BPipeline.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Microservice deployment pipeline (without A/B testing)</td></tr></tbody></table><div><b><u>Build the app (after commit)</u></b></div><div><br /></div><div>Most preferably we would like after each merge of a PR trigger the deployment pipeline (thus do Continuous Deployment).&nbsp;</div><div><br /></div><div>The result of this step would be to have the application tested in the following ways:</div><div><ul><li>unit and integration tests are ran</li><li>validity of declared stubs specifications is tested against the application itself</li></ul></div><div>Finally what is published to Nexus is the fat-jar of the application together with its stubs.&nbsp;</div><div><br /></div><div><b><u>Deploy to staging</u></b></div><div><br /></div><div>We deploy our freshly built application to the staging environment. <a href="https://github.com/4finance/micro-infra-spring/wiki/Stub-runner">Micro Infra Spring Stub-runner</a> is responsible for downloading the current <b>development</b>&nbsp;versions of stubs of declared dependencies of the microservice.&nbsp;</div><div><br /></div><div>In the first version of the pipeline we've decided to go towards development versions since we would like each of the applications to go live after each commit. That means that there is a high probability that the development version of a stub is in fact the production one. Of course that not necessarily needs to be true - but this is our trade off.</div><div><br /></div><div>In the future versions of the pipeline we would like to test the app against both development and production versions of stubs.&nbsp;</div><div><br /></div><div><b>What is very important to see is that in this step we are upgrading the microservice's DB schema.</b></div><div><b><br /></b></div><div><b><u>Test application rollback scenario</u></b></div><div><br /></div><div>We don't want to rollback the database. If you have MongoDB like databases there is no schema in fact. If you have Liquibase - you can provide the rollback scripts for relational DBs. They however introduce complexity on the DB level.</div><div><br /></div><div>We've decided to go with a trade off that the complexity goes out from the DB level to the code. We're not rolling back the DB but we're rolling back the application. That means that the developers need to write their code to support backwards compatibility.&nbsp;</div><div><br /></div><div><b>That means that the NEW version of the application MUST support the OLD schema of the database. Also developers MUST NOT do backwards incompatible changes in subsequent liquibase scripts.</b></div><div><b><br /></b></div><div>We're running old smoke tests on the rolled back version of the application that is connected to the new version of the schema. That way we can ensure that most probably we will be able to rollback on production without greater issues.</div><div><br /></div><div><b><u>Deploy to production</u></b></div><div><br /></div><div>If the smoke tests have passed and we've checked the rollback procedures we can go live. Here the monitoring part comes in. We need to ensure that we've put all the KPI checking alerts in place. As a part of deployment procedure a review of monitoring and alerts needs to take place.</div><div><br /></div><div>As you can see in the picture the first scenario of live deployment doesn't include 0 downtime approach. That was yet another trade off that we've decided to take. We don't want to tackle the issue of automatic data migration right now. Also for the developers writing code that supports both old and new schema is actually mind blowing. That's why we want to do things a step at a time - for now we kill all the application instances on production, boot one up and &nbsp;change the schema and then boot the rest up too.</div><div><br /></div><br /><div class="separator" style="clear: both; text-align: left;"><b><u>Rollback procedure</u></b></div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">If our KPI monitoring starts to go all red on production then we need to rollback as fast as possible. Since we've tested the rollback procedure it shouldn't be an issue on production to kill all the instances, download the previous version of the app and run it against the new schema.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><h4 style="clear: both; text-align: left;">Summary</h4><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">As everything related to distributed systems - you can see that microservice deployment is not easy. Actually it's full of trade offs and complexity. Starting from the infrastructure going through testing and finishing with database schema changes.</div><div class="separator" style="clear: both; text-align: left;"><br /></div><div class="separator" style="clear: both; text-align: left;">The presented solution seems to be an acceptable compromise between time, effort, certainty and feedback.</div></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to Speed Up Your Gradle Build From 90 to 8 Minutes]]></title>
    <link href="http://toomuchcoding.com/blog/2015/02/08/how-to-speed-up-your-gradle-build-from/"/>
    <updated>2015-02-08T10:24:00-08:00</updated>
    <id>http://toomuchcoding.com/blog/2015/02/08/how-to-speed-up-your-gradle-build-from</id>
    <content type="html"><![CDATA[<div class='post'>
<div style="background-color: white; box-sizing: border-box; color: #262626; font-family: Georgia, serif; font-size: 19px; line-height: 27.55px;">Even though I was supposed to write a series of blog posts about&nbsp;<a href="http://toomuchcoding.blogspot.com/search/label/micro-infra-spring" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">micro-infra-spring</a>&nbsp;here at&nbsp;<a href="http://toomuchcoding.blogspot.com/" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">Too Much Coding blog</a>, today I'll write about how we've managed to decrease our biggest project's build time from 90 to 8 minutes!<br /><br /><a name='more'></a>
<!--more-->
  <br style="box-sizing: border-box;" /><br /><br style="box-sizing: border-box;" />At one of the companies that I've been working we've faced a big problem related to pull request build times. We have one monolithic application that we are in progress of slicing into microservices but still until this process is finished we have to build that big app for each PR. We needed to change things to have really fast feedback from our build so that pull request builds don't get queued up endlessly in our CI. You can only imagine the frustration of developers who can't have their branches merged to master because of the waiting time.<br /><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Structure</strong></div>In that project we have over 200 Gradle modules and over a dozen big projects (countries) from which we can build some (really fat) fat-jars. We have also a core module that if we change then we would have to rebuild all the big projects to check if they weren't affected by the modifications. There are a few old countries that are using GWT compilers and we have some JS tasks executed too.<br /><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Initial stats</strong></div>Before we started to work on optimization of the process the whole application (all the countries) was built in about 1h 30 minutes.<br /><br style="box-sizing: border-box;" /><i style="box-sizing: border-box;">Current build time: ~90 minutes.</i></div><div style="background-color: white; box-sizing: border-box; color: #262626; font-family: Georgia, serif; font-size: 19px; line-height: 27.55px;"><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Profile your build</strong></div>First thing that we've done was to run the build with the&nbsp;--profile&nbsp;switch.<br /><br style="box-sizing: border-box;" />That way Gradle created awesome stats for our build. If you are doing any sort of optimization then it's crucial to gather measurements and statistics. Check out this&nbsp;<a href="https://gradle.org/docs/current/userguide/tutorial_gradle_command_line.html#sec:profiling_build" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">Gradle page about profiling your build&nbsp;</a>for more info on that switch and features.</div><div style="background-color: white; box-sizing: border-box; color: #262626; font-family: Georgia, serif; font-size: 19px; line-height: 27.55px;"><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Exclude long running tasks in dev mode</strong></div><div style="box-sizing: border-box;"><span data-fr-verified="true" style="background-color: initial; box-sizing: border-box;"><span data-fr-verified="true" style="box-sizing: border-box; line-height: 1.45em;"><span data-fr-verified="true" style="box-sizing: border-box; font-size: 15px;"><span data-fr-verified="true" style="box-sizing: border-box; font-family: &quot;arial&quot; , &quot;helvetica&quot; , &quot;verdana&quot; , &quot;tahoma&quot; , sans-serif;">It turned out that we are spending a lot of time on JS minification and on GWT compilation. That's why we have added a custom property&nbsp;-PdevMode&nbsp;to disable some long running tasks in dev mode build. Those tasks were:</span></span></span></span></div><br style="box-sizing: border-box;" /><ul style="box-sizing: border-box; margin-bottom: 10px; margin-top: 0px; padding-left: 25px;"><li style="box-sizing: border-box; padding: 0px 0px 8px;">excluded JS minification</li><ul style="box-sizing: border-box; margin-bottom: 0px; margin-top: 0px; padding-left: 25px;"><li style="box-sizing: border-box; padding: 0px 0px 8px;">benefit: 13 countries * ~60 secs * at least 2 modules where minification occurred ~ 26 minutes</li></ul><li style="box-sizing: border-box; padding: 0px 0px 8px;">optimized GWT compilation:&nbsp;</li><ul style="box-sizing: border-box; margin-bottom: 0px; margin-top: 0px; padding-left: 25px;"><li style="box-sizing: border-box; padding: 0px 0px 8px;">have permutations done for only 1 browser (by default it's done for multiple browsers)</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">disable optimization of the compilation (-optimize 0)</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">add the -draftCompile switch to to compile quickly with minimal optimizations</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">benefit: about 2 minutes less on GWT compilation * sth like 5 projects with GWT ~ 10 minutes</li></ul></ul><i style="box-sizing: border-box;">Overall gain: ~ 40 minutes.</i><br /><div style="box-sizing: border-box;"><em style="box-sizing: border-box;">Current build time: ~50 minutes.</em></div><div style="box-sizing: border-box;"><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Check out your tests</strong></div>Together with the one and only&nbsp;<a href="http://github.com/achudzik" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">Adam Chudzik</a>&nbsp;we have started to write our own&nbsp;<a href="https://github.com/marcingrzejszczak/gradle-test-profiler" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">Gradle Test Profiler</a>&nbsp;(it's a super beta version ;) ) that created a single CSV with sorted tests by their execution time. We needed quick and easy gains without endless test refactoring and it turned out that it's really simple. One of our tests took 50 seconds to execute and it was testing a feature that has and will never be turned on on production. Of course there were plenty of other tests that we should take a look into (we'd have to look for test duplication, check out the test setup etc.) but it would involve more time, help of a QA and we needed quick gains.<br /><br style="box-sizing: border-box;" />Benefit: By simple disabling this test we gained about 1 minute.<br /><i style="box-sizing: border-box;">Overall gain: ~ 41 minutes.</i><br /><div style="box-sizing: border-box;"><em style="box-sizing: border-box;">Current build time: ~49 minutes.</em></div><div style="box-sizing: border-box;"><br style="box-sizing: border-box;" /></div><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Turn on the --parallel Gradle flag at least for the compilation</strong></div>Even though at this point our gains were more or less 40 minutes it was still unacceptable for us to wait 40 minutes for the pull request to be built.<br /><br style="box-sizing: border-box;" />That's why we decided to go parallel! Let's build the projects (over 200) in parallel and we'll gain a lot of time on that. When you execute the Gradle build with the --parallel flag Gradle calculates how many threads can be used to concurrently build the modules. For more info go to the&nbsp;<a href="https://gradle.org/docs/current/userguide/multi_project_builds.html#sec:parallel_execution" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">Gradle's documentation on parallel project execution</a>.<br /><br style="box-sizing: border-box;" />It's an incubating feature so wen we started to get&nbsp;BindExceptions&nbsp;on port allocation we initially thought that most likely it's Gradle's fault. Then we had a chat with&nbsp;<a href="https://twitter.com/szczepiq" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">Szczepan Faber</a>who worked for Gradleware and it turns out that the feature is actually really mature (thx Szczepan for the help BTW :) ).<br /><br style="box-sizing: border-box;" />We needed quick gains so instead of fixing the port binding stuff we decided only to compile everything in parallel and then run tests sequentially.</div><div style="box-sizing: border-box;"><br />Benefit: By doing this lame looking hack we gained ~4 mintues (on my 8 core laptop).<br /><i style="box-sizing: border-box;">Overall gain: ~ 45 minutes.</i><br /><div style="box-sizing: border-box;"><em style="box-sizing: border-box;">Current build time: ~45 minutes.</em></div><div style="box-sizing: border-box;"><br style="box-sizing: border-box;" /></div><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Don't be a jerk - just prepare your tests for parallelization</strong></div>This command seemed so lame that we couldn't even look at it. That's why we said - let's not be jerks and just fix the port issues.<br /><br style="box-sizing: border-box;" />So we went through the code, randomized all the fixed ports, patched&nbsp;<a href="http://github.com/4finance/micro-infra-spring" style="background: transparent; box-sizing: border-box; color: black; cursor: pointer; text-decoration: none;">micro-infra-spring</a>&nbsp;so it does the same upon Wiremock and Zookeeper instantiation and just ran the building of the project like this:<br /><br style="box-sizing: border-box;" />We were sure that this is the killer feature that we were lacking and we're going to win the lottery. Much to our surprise the result was really disappointing.<br /><br style="box-sizing: border-box;" />Benefit: Concurrent project build decreased the time by ~5 minutes.<br /><i style="box-sizing: border-box;">Overall gain: ~ 50 minutes.</i><br /><div style="box-sizing: border-box;"><em style="box-sizing: border-box;">Current build time: ~40 minutes.</em></div><div style="box-sizing: border-box;"><br style="box-sizing: border-box;" /></div><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Check out your project structure</strong></div>You can only imagine the number of WTFs that were there in our office. How on earth is that possible?<br /><br style="box-sizing: border-box;" />We've opened up&nbsp;htop,&nbsp;iotop&nbsp;and all the possible tools including&nbsp;vmstat&nbsp; to see what the hell was going on. It turned out that context switching is at an acceptable level whereas at some point of the build only part of the cores are used as if sth was executed sequentially!<br /><br style="box-sizing: border-box;" />The answer to that mystery was pretty simple. We had a wrong project structure.<br /><br style="box-sizing: border-box;" />We had a module that ended up as a test-jar in&nbsp;testCompile&nbsp;dependency of other projects. That means that the vast majority of modules where waiting for this project to be built. Built means compiled and tested. It turned out that this test-jar module had also plenty of slow integration tests in it so only after those tests were executed could other modules be actually built!<br /><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Simple source moving can drastically increase your speed</strong></div>By simply moving those slow tests to a separate module we've unblocked the build of all modules that were previously waiting.<br /><br style="box-sizing: border-box;" />Now we could do further optimization - we've split the slow integration tests into two modules to make all the modules in the whole project be built in more or less equal time (around 3,5 minutes).<br />.<br />Benefit: Fixing the project structure decreased the time by ~10 minutes<br /><i style="box-sizing: border-box;">Overall gain: ~ 60 minutes.</i><br /><div style="box-sizing: border-box;"><em style="box-sizing: border-box;">Current build time: ~30 minutes.</em></div><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Don't save on machine power</strong></div><div style="box-sizing: border-box;"><span data-fr-verified="true" style="background-color: initial; box-sizing: border-box;"><span data-fr-verified="true" style="box-sizing: border-box; line-height: 1.45em;"><span data-fr-verified="true" style="box-sizing: border-box; font-size: 15px;"><span data-fr-verified="true" style="box-sizing: border-box; font-family: &quot;arial&quot; , &quot;helvetica&quot; , &quot;verdana&quot; , &quot;tahoma&quot; , sans-serif;">We've invested in some big AWS instance with 32 cores and 60 gb of RAM to really profit from the parallel build's possibilities. We're paying about 1.68$ per one hour of such machine's (c3.8xlarge) working time.</span></span></span></span></div><br style="box-sizing: border-box;" />If someone form the management tells you that that machine costs a lot of money and the company can't afford it you can actually do a fast calculation. You can ask this manager what is more expensive - paying for the machine or paying the developer for 77 minutes * number of builds of waiting?<br /><br style="box-sizing: border-box;" />Benefit: Paying for a really good machine on AWS decreased the build time by ~22 minutes<br /><i style="box-sizing: border-box;">Overall gain: ~ 82 minutes.</i><br /><div style="box-sizing: border-box;"><em style="box-sizing: border-box;">Current build time: ~8 minutes.</em></div><div style="box-sizing: border-box;"><br style="box-sizing: border-box;" /></div><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">What else can we do?</strong></div>Is that it? Can we decrease the time further on? Sure we can!<br /><br style="box-sizing: border-box;" />Possible solutions are:<br /><br style="box-sizing: border-box;" /><ul style="box-sizing: border-box; margin-bottom: 10px; margin-top: 0px; padding-left: 25px;"><li style="box-sizing: border-box; padding: 0px 0px 8px;">Go through all of the tests and check why some of them take so long to run</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">Go through the integration tests and check if don't duplicate the logic - we will remove them</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">We're using Liquibase for schema versioning and we haven't merged the changests for some time thus sth like 100 changesets are executed each time we boot up Spring context (it takes more or less 30 seconds)</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">We could limit the Spring context scope for different parts of our applications so that Spring boots up faster</li><li style="box-sizing: border-box; padding: 0px 0px 8px;">Buy a more powerful machine ;)</li></ul><div style="box-sizing: border-box;">There is also another, better way ;)</div><div style="box-sizing: border-box;">SPLIT THE MONOLITH INTO MICROSERVICES AND GO TO PRODUCTION IN 5 MINUTES ;)</div><br style="box-sizing: border-box;" /><div style="box-sizing: border-box; margin-bottom: 15px; margin-top: 5px;"><strong style="box-sizing: border-box;">Summary</strong></div>Hopefully I've managed to show you how you can really speed up your build process. The work to be done is difficult, sometimes really frustrating but as you can see very fruitful.</div></div></div>

]]></content>
  </entry>
  
</feed>
